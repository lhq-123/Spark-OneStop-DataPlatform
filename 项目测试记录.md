[TOC]



# 1.Sqoop抽取数据格式问题

查看Oracle中CISS_SERVICE_WORKORDER表的数据条数

```sql
select count(1) as cnt from CISS_SERVICE_WORKORDER;
```

采集CISS_SERVICE_WORKORDER的数据到HDFS上

```shell
sqoop import \
--connect jdbc:oracle:thin:@oracle.bigdata.cn:1521:helowin \
--username ciss \
--password 123456 \
--table CISS4.CISS_SERVICE_WORKORDER \
--delete-target-dir \
--target-dir /test/full_imp/ciss4.ciss_service_workorder \
--fields-terminated-by "\001" \
-m 1
```

Hive中建表查看数据条数

```shell
启动Hive容器:
docker start hive
使用DBeaver EE连接并创建测试表:
create external table test_text(
line string
)
location '/test/full_imp/ciss4.ciss_service_workorder';
统计行数:
select count(*) from test_text;
```

Sqoop采集完成后导致HDFS数据与Oracle数据量不符

原因:

- sqoop以文本格式导入数据时，默认的换行符是特殊字符
- Oracle中的数据列中如果出现了\n、\r、\t等特殊字符，就会被划分为多行

解决方案:

- 方案一：删除或者替换数据中的换行符
  - --hive-drop-import-delims：删除换行符
  - --hive-delims-replacement  char：替换换行符
  - 不建议使用：侵入了原始数据
- 方案二：使用特殊文件格式：AVRO格式

```shell
sqoop import \
-Dmapreduce.job.user.classpath.first=true \
--connect jdbc:oracle:thin:@oracle.bigdata.cn:1521:helowin \
--username ciss \
--password 123456 \
--table CISS4.CISS_SERVICE_WORKORDER \
--delete-target-dir \
--target-dir /test/full_imp/ciss4.ciss_service_workorder \
--as-avrodatafile \ #使用AVRO格式存储数据
--fields-terminated-by "\001" \
-m 1
```

| 数据格式     | 介绍                                                         |
| ------------ | ------------------------------------------------------------ |
| TextFile     | Hive默认的文件格式，最简单的数据格式，便于查看和编辑，耗费存储空间，I/O性能较低 |
| SequenceFile | 含有键值对的二进制文件，优化磁盘利用率和I/O，并行操作数据，查询效率高，但存储空间消耗最大 |
| AvroFile     | 特殊的二进制文件，设计的主要目标是为了满足schema evolution，Schema和数据保存在一起 |
| OrcFile      | 列式存储，Schema存储在footer中，不支持schema evolution，高度压缩比并包含索引，查询速度非常快 |
| ParquetFile  | 列式存储，与Orc类似，压缩比不如Orc，但是查询性能接近，支持的工具更多，通用性更强 |

因为开发采用的是SparkSQL(数据文件+Schema),所以在Ingest这一层使用AVRO格式存储数据